# 2025-08-03 작업 로그

## 📝 오늘 한 일
- 'LLM Inference Lab' 프로젝트 기획
- 왜 이 튜토리얼을 만드는지 목적 재정의
- 프로덕션 관점에서 벤치마킹할 자료 조사

## 🧐 오늘의 메모/생각
- 프로덕션 LLM은 단순 추론과 달리 성능, 비용, 장애 대응 등 현실적 고민이 많다
- 기존 튜토리얼이 기술 설명 위주라서, 시행착오와 고민을 기록하는 것이 차별점이 될 것

## 📚 오늘 참고한 자료
### 블로그/아티클
- [Databricks: LLM Inference Performance Engineering](https://www.databricks.com/blog/llm-inference-performance-engineering-best-practices)
- [NVIDIA: Mastering LLM Techniques](https://developer.nvidia.com/blog/mastering-llm-techniques-inference-optimization/)
- [Baseten: Guide to LLM Inference](https://www.baseten.co/blog/llm-transformer-inference-guide/)
- [LaunchDarkly: LLM Inference Optimization](https://launchdarkly.com/blog/llm-inference-optimization/)

### 오픈소스/GitHub
- [vllm-project/vllm](https://github.com/vllm-project/vllm)
- [bentoml/OpenLLM](https://github.com/bentoml/OpenLLM)
- [tensorzero/tensorzero](https://github.com/tensorzero/tensorzero)
- [Hannibal046/Awesome-LLM](https://github.com/Hannibal046/Awesome-LLM)
- [horseee/Awesome-Efficient-LLM](https://github.com/horseee/Awesome-Efficient-LLM)
